<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js – The HTML Presentation Framework</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">

<style>
    {
        box-sizing: border-box;
    }
/* Set additional styling options for the columns */
    .column {
    float: left;
    }

/* Set width length for the left, right and middle columns */
    .left {
    width: 50%;
    }

    .middle {
    width: 20%;
    }
    
    .right {
    width: 50%;
    }

    .row:after {
    content: "";
    display: table;
    clear: both;
    }
</style>


</head>

<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">

<!-- URL Slide -->
<section>
    <p> http:</small>//bit.ly/Phys141_2</p> 
</section>

<!-- Psychometric Curves -->

<section data-background="#FFFFFF">
    <p>Psychophysics</p>
    <img src=" assets2/responsecurves.png " width="60%"> 
    <p align="justify" style="font-size:15px">  
    The psychometric curve. A. The psychometric function plots the percentage of stimuli detected by a human observer as a function of stimulus magnitude. Threshold is defined as the stimulus intensity detected on 50% of the trials. B. Detection and discrimination thresholds depend on the criteria used by individual subjects. Where an ‘ideal’ observer correctly detects the presence and absence of stimuli at the response threshold with equal probability (curve b), an observer who is told to respond to the slightest indication of a stimulus may report many false positives when no stimuli occur and has a lower response threshold (curve a). An observer who is told to respond only when very certain that a stimulus has occurred reports more hits than false positives and has a higher response thresholds (curve c). 
    </p>
</section>

<!-- 2AFC paradigm  -->

<section data-background="#FFFFFF">
    <p> Two-alternative forced choice tasks.  </p>
    <div class="row">
        <div class="column left">
            <img src="assets2/responsegrid.png " width="80%">
        </div>
        <div class="column right" >
            <br>
            <p align="justify" style="font-size:20px">  
            The stimulus-response matrix for a stimulus detection task (yes-no) or a categorical judgment task (red-blue). Although there are two possible stimuli and two possible responses, the data represent conditional probabilities in which the experimenter controls the stimuli and measures the subject's responses. The numbers provide examples of behavioral data obtained from a strict observer who responds "yes" less often than the actual frequency of occurrence of the stimulus.
        </p>
        </div>
    </div>
</section>

<!-- Variability of sensations Slide -->

<section>
    <p align="left" style="font-size:30px">  
    The variability of sensations evoked by a stimulus can be represented with a normal probability function with a mean ($\mu$) and standard deviation ($\sigma$): <br>
    \[ f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}}\]
    </p>
</section>

<!-- Decision Boundary Slide -->

<section data-background="#FFFFFF">
    <p> Gaussian stimulus magnitudes.  </p>
    <div class="row">
        <div class="column left">
            <img src="assets2/gaussiandiscrimination.png" width="100%">
        </div>
        <div class="column right" >
            <p align="justify" style="font-size:20px">  
            <br>
            Stimulus magnitudes can be represented by Gaussian curves with standard deviations that measure the fluctuation in sensations from trial to trial. The discriminability of a pair of stimuli is correlated with the distance between the two curves. When two stimuli are similar in magnitude, the two Gaussian curves overlap and no single criterion allows error-free responses. 
            </p>
        </div>
    </div>
    <p align="justify" style="font-size:20px">  
    An <em> ideal observer  </em> maximizes the number of correct responses and minimizes the total errors, setting the decision boundary at the intersection of the two curves. <br>
    <br>
    A <em> strict observer  </em> minimizes the number of false positives but also reduces the total hits, setting the decision boundary to the right (solid line). <br>
    <br>
    A <em> lax observer  </em> maximizes the number of hits but also increases the total false positives, setting the decision boundary to the left of the ideal subject.<br>
    <br>
</section>

<section>
    <p> Flynculus </p> 
        <img src="assets2/flynculus.png" width="60%">
</section>

<section data-background="#FFFFFF">
    <p> Physiology </p>
            <img src="assets2/adrianmuscle.png" width="40%">
            <p align="justify" style="font-size:20px">  
Adrian and Zotterman measured the relation between the force applied to a muscle and the firing rate in a stretch receptor embedded in the muscle. Different forces were generated by hanging weights with different masses from the muscle. This type of experiment established that the frequency of firing in sensory neurons increased with increasing stimulus strength.
            </p>
</section>
<section data-background="#FFFFFF">
    <p> Physiology </p>
            <img src=" assets2/Fain1_actionpotentials.png " width="90%">
            <p align="justify" style="font-size:20px">  
                Action potentials from the lateral eye of the horseshoe crab <em> Limulus </em>. Each trace gives the response to a different light intensity, which was systematically increased by an additional factor of ten from dimmest (bottom) to brightest (top).
            </p>
</section>

<!-- Bayes Theorem Slide -->

<section>
    <p> Bayes' theorem </p>
    <p align="center" style="font-size:30px">  
       \[ P(A\mid B)={\frac {P(B\mid A)P(A)}{P(B)}} \]
       <br> 
       where $A$ and $B$ are events and $P(B)\neq 0$.
       <br> 
       <br> 
    </p>

    <p align="left" style="font-size:20px">  
     $\bullet$ $P(A\mid B)$ is a <em> conditional probability </em>: the probability of event $A$ occurring given that $B$ is true. 
    <br>
    <br>
     $\bullet$ $P(B\mid A)$ is also a conditional probability: the probability of event $B$ occurring given that $A$ is true.
    <br>
    <br>
     $\bullet$ $P(A)$ and $P(B)$ are the probabilities of observing $A$ and $B$ respectively without any given conditions; they are also known as the marginal probability or prior probability.
    <br>
    <br>
    </p>
</section>

<section>
    <p> Proof of Bayes' theorem </p>
    <div class="row">
        <div class="column left">
            <p align="left" style="font-size:25px">  
                $ P(A\mid B)={\frac {P(A\cap B)}{P(B)}} \text{, if } P(B)\neq 0 $
            </p>
        </div>
        <div class="column right">
            <p align="left" style="font-size:25px">  
                $P(B\mid A)={\frac {P(B\cap A)}{P(A)}} \text{, if }P(A)\neq 0$
            </p>
        </div>
    </div>
    <p align="left" style="font-size:25px">  
        <br> 
        <br> 
        Solving for $P(A\cap B)$ and substituting into the above expression for $P(A\mid B)$ yields Bayes' theorem:
       <br> 
        \[ P(A\mid B)={\frac {P(B\mid A)P(A)}{P(B)}} \text{ if }P(B)\neq 0 \]
       <br> 
       <br> 
    </p>
</section>

<section data-background="#FFFFFF">
    <p>The Boltzmann Distribution</p>
    <div class="row">
        <div class="column left">
            <img src=" assets3/exponentialdistribution.png " width="80%"> 
        </div>
        <div class="column middle">
            <p align="left" style="font-size:20px">  
                &nbsp;&nbsp;&nbsp;&nbsp; 
            </p>
        </div>
        <div class="column right">
            <p align="left" style="font-size:20px">  
                A Boltzmann distribution is a probability distribution that gives the probability that a system will be in a certain state as a function of state energy and temperature:<br>

                \[ p_{i}\propto e^{-{\varepsilon _{i}}/{(kT)}} \] 

                where $p_i$ is the probability of the system being in state $i$, $\varepsilon_i$ is the energy of that state, and a constant $kT$ of the Boltzmann constant and temperature T.<br><br>
                $k_B = 1.4 \times 10^{-23}$ J/K <br><br>
                $k_{B}T \approx 4 \times 10^{-21}$ J <br><br>
                The energy of one blue-green photon ($\lambda$=500 nm) is $4 \times 10^{-19}$ J.<br><br>
            </p>
        </div>
    </div>
</section>

<section>
    <p>The Boltzmann Factor</p>
    <p align="justify" style="font-size:25px">  
        The ratio of probabilities of two states is the Boltzmann factor:<br><br>

        \[ {\frac {p_{i}}{p_{j}}}=e^{{(\varepsilon _{j}-\varepsilon _{i})}/{(kT)}} \] 

        If a system has $M$ possible states, the sum of the state probabilities is normalized:<br><br>

         \[ \sum_{j=1}^{M}{p_i}=1 \]

        The probability of being in each state: <br><br>

        \[ p_{i}={\frac {1}{Q}}e^{-{\varepsilon }_{i}/(kT)}={\frac {e^{-{\varepsilon }_{i}/(kT)}}{\sum _{j=1}^{M}{e^{-{\varepsilon }_{j}/(kT)}}}} \]
    </p>
</section>

<section data-background="#000000">
    <p>The Exponential Atmosphere</p>
    <div class="row">
        <div class="column left">
            <img src=" assets3/Exponentialatmosphere.png " width="80%"> 
            <p align="left" style="font-size:20px">  
                From <em> Feynman's Lectures in Physics.</em> <br><br>
                Mass of one oxygen molecule is $5\times10^{-23}$ g.  <br>
                Mass of one hydrogen molecule is $3\times10^{-24}$ g.<br>
                Does Feynman's drawing make sense?<br>
            </p>
        </div>
        <div class="column middle">
            <p align="left" style="font-size:20px">  
                &nbsp;&nbsp;&nbsp;&nbsp; 
            </p>
        </div>
        <div class="column right">
            <p align="justify" style="font-size:20px">  
                The altitude of each gas molecule is associated with a gravitational potential energy: $E=mgh$.<br><br>
                Assuming a uniform atmospheric temperature $T$, the probability that a molecule is at height $h$ is:<br>

                \[ p(h) \propto e^{-mgh/kT} \]

                For this probability density to be properly normalized:<br>

                \[ p(h) = \frac{e^{-mgh/kT}}{\int_{h=0}^{\infty} e^{-mgh/kT}dh} \]
            </p>
            <p align="justify" style="font-size:20px; color:yellow">  
                The expectation value for the altitude of a gas molecule depends on its mass: $ \left< h \right> = \frac{kT}{mg} $.
            </p>
        </div>
    </div>
</section>

<section data-background="#000000">
    <p>Deriving Boltzmann </p>
    <div class="row">
        <div class="column left">
            <img src=" assets3/thermalenergy.png " width="100%"> 
            <p align="center" style="font-size:20px">  
                $N$ weakly interacting systems divide total $E$ energy among them<br>
            </p>
        </div>
        <div class="column middle">
            <p align="left" style="font-size:20px">  
                &nbsp;&nbsp;&nbsp;&nbsp; 
            </p>
        </div>
        <div class="column right">
            <p align="justify" style="font-size:20px">  
                Say that you have $N$ particles that are given a total amount of energy $E$.<br><br>
                These particles are able to freely exchange energy among them, but are constrained to quantal energy levels.<br><br>
                How many particles can you expect to find at each energy level?<br><br>
                What is the probability of a particle having a certain amount of energy?<br><br>
            </p>
        </div>
    </div>
</section>

<section data-background="#000000">
    <p>Deriving Boltzmann </p>
    <div class="row">
        <div class="column left">
            <img src=" assets3/thermalenergy.png " width="100%"> 
            <p align="center" style="font-size:20px">  
                $N$ weakly interacting systems divide total $E$ energy among them<br>
            </p>
        </div>
        <div class="column middle">
            <p align="left" style="font-size:20px">  
                &nbsp;&nbsp;&nbsp;&nbsp; 
            </p>
        </div>
        <div class="column right">
            <p align="left" style="font-size:20px">  
                <br>
                <br>
                <br>
                Mass Conservation: 
                $ \sum_{s} n_s = N $<br><br>
                Energy Conservation: 
                $ \sum_{s} n_s \varepsilon_s = E $<br><br>
                Probability of being in state $s$:
                $ p_s=n_s/N $<br><br>
                Normalization condition: 
                $ \sum_s p_s = 1 $<br><br>
                Average Energy of a Particle:
                \[ \left< \varepsilon \right> = \sum_s p_s \varepsilon_s =\frac{\sum_s n_s\varepsilon_s}{\sum_sn_s} \]
            </p>
        </div>
    </div>
</section>

<section>
    <p>Deriving Boltzmann </p>
    <div class="row">
        <div class="column left">
            <table style="border:hidden; font-size:30px">
                <thead>
                    <th align="center" > State</th>
                    <th align="center" >Energy</th>
                    <th align="center" >Number</th>
                </thead>  
                <tbody>
                  <tr>
                    <td align="center">1</td>
                    <td align="center">$\varepsilon_1$</td>
                    <td align="center">$n_1$</td>
                  </tr>
                  <tr>
                    <td align="center">2</td>
                    <td align="center">$\varepsilon_2$</td>
                    <td align="center">$n_2$</td>
                  </tr>
                  <tr>
                    <td align="center">3</td>
                    <td align="center">$\varepsilon_3$</td>
                    <td align="center">$n_3$</td>
                  </tr>
                  <tr>
                    <td align="center">.</td>
                    <td align="center">.</td>
                    <td align="center">.</td>
                  </tr>
                  <tr>
                    <td align="center">.</td>
                    <td align="center">.</td>
                    <td align="center">.</td>
                  </tr>
                  <tr>
                    <td align="center">$s$</td>
                    <td align="center">$\varepsilon_s$</td>
                    <td align="center">$n_s$</td>
                  </tr>
                  <tr>
                    <td align="center">.</td>
                    <td align="center">.</td>
                    <td align="center">.</td>
                  </tr>
                  <tr>
                    <td align="center">.</td>
                    <td align="center">.</td>
                    <td align="center">.</td>
                  </tr>
                </tbody>
            </table> 
            <p align="center" style="font-size:20px; color:yellow">  
                What is the probability of an $n_s$ distribution?<br>
            </p>
        </div>
        <div class="column middle">
            <p align="left" style="font-size:20px">  
                &nbsp;&nbsp;&nbsp;&nbsp; 
            </p>
        </div>
        <div class="column right">
            <p align="left" style="font-size:20px">  
            The number of ways you can arrange a number of particles at each energy level is given by combinatorics:
                \[ W=\frac{N!}{n_1!n_2!n_3!...} \]
            We need to maximize $\log{W}$<br>
                \[ \log{W} = \log{N!}-\sum_s \log{n_s!}  \]
            Stirling's formula<br>
                 \[ N!=\left( \frac{N}{e} \right)^N \]
            </p>
            <p align="left" style="font-size:20px; color:green">  
            <b> No more factorials!<br> </b> 
                \[ \log{W} = N(\log N -1 ) - \sum_s n_s (\log n_s -1 )\]
            </p>
        </div>
    </div>
</section>

<section data-background="#000000">
    <p>Lagrange Multipliers</p>
    <div class="row">
        <div class="column left">
            <img src=" assets3/lagrange.png " width="100%"> 
        </div>
        <div class="column middle">
            <p align="left" style="font-size:20px">  
                &nbsp;&nbsp;&nbsp;&nbsp; 
            </p>
        </div>
        <div class="column right">
            <p align="left" style="font-size:20px;">  
                For the function $w=f(x,y,z)$ constrained by $g(x,y,z)=c$, the maxima and minima are those points where $\nabla f$ is parallel to $\nabla g$:
    
                \[ \nabla f - \lambda \nabla g = 0 \]
            </p>
        </div>
    </div>
</section>

<section>
    <p>Lagrange Multipliers</p>
            <p align="left" style="font-size:20px;">  
                     Add $N$ (Conservation of Mass) and $E$ (Conservation of Energy) to $\log{W}$, each multiplied by a Lagrange multiplier ($\alpha$ and $\beta$). The most probable $W$ is that for which:<br><br>
                     \[ \frac{d}{dn_s} \left(\log{W} - \alpha \sum_s n_s - \beta \sum_s \varepsilon_s n_s \right) = 0 \]<br>
            </p>
            <p align="center" style="font-size:20px;">  
                     Calculating for each $n_s$ gives:<br>
                     \[ \log{n_s}+ \alpha + \beta \varepsilon_s = 0 \]<br>
            </p>
            <p align="center" style="font-size:25px; color:yellow">  
                     The Boltzmann distribution:<br>
                     \[ n_s =e^{-\alpha}e^{-\beta \varepsilon_s} \]
            </p>
</section>

<section>
<section>
    <p> Claude Shannon </p> 
        <img src="assets2/shannon.png" width="80%">
</section>
<section>
    <p> Mathematical theory of communication </p> 
        <img src="assets2/shannonreceiver.png" width="80%">
</section>
</section>

<section data-background="#000000">
    <p>Shannon Entropy</p>
    <div class="row">
        <div class="column left">
            <img src=" assets3/entropycoincropped.png " width="100%"> 
            <p align="center" style="font-size:20px;">  
                Entropy of a coin toss
            </p>
        </div>
        <div class="column middle">
            <p align="left" style="font-size:20px">  
                &nbsp;&nbsp;&nbsp;&nbsp; 
            </p>
        </div>
        <div class="column right">
            <p align="left" style="font-size:20px;">  
                 The entropy $H(X)$ of a random variable $X$
                     \[ H(X)=-\sum_{x \in X}^{} p(x) \log_2{p(x)} \]
                     \[ H(X)=\left< \log_2{p(x)} \right>  \]<br>
                 The entropy of a two-state system
                     \[ H(X)= -p_A \log_2{p_A} -p_B \log_2{p_B} \]
            </p>
        </div>
    </div>
</section>

<section>
    <p>Maximize Shannon Entropy with Lagrange Multipliers</p>
    <div class="row">
        <div class="column left">
            <p align="left" style="font-size:20px;">  
                    Maximize entropy: 
                    \[ H(p)=-\sum_{i=1}^{N} p_i \log{p_i} \]
                    Normalization constraint: 
                    \[ \sum_{i=1}^{N} p_i = 1 \]
                    Fixed mean energy constraint: 
                    \[ \sum_{i=1}^{N} p_i \varepsilon_i = E \]
            </p>
        </div>
        <div class="column middle">
            <p align="left" style="font-size:20px">  
                &nbsp;&nbsp;&nbsp;&nbsp; 
            </p>
        </div>
        <div class="column right">
            <p align="left" style="font-size:25px; color:yellow">  
                    The Boltzmann Distribution
                    \[ p_i \propto e^{-\lambda \varepsilon_i} \]<br>
            </p>
            <p align="left" style="font-size:25px; color:green">  
             <b> An exponential distribution of energies is the distribution with the least bias. </b> 
            </p>
        </div>
    </div>
</section>

</div>

</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/zoom/zoom.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/search/search.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>

			// Also available as an ES module, see:
			// https://revealjs.com/initialization/
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight ]
			});

		</script>

		<script src="dist/reveal.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			Reveal.initialize({
				history: true,
				transition: 'linear',

				mathjax2: {
					config: 'TeX-AMS_HTML-full',
					TeX: {
						Macros: {
							R: '\\mathbb{R}',
							set: [ '\\left\\{#1 \\; ; \\; #2\\right\\}', 2 ]
						}
					}
				},

				// There are three typesetters available
				// RevealMath.MathJax2 (default)
				// RevealMath.MathJax3
				// RevealMath.KaTeX
				//
				// More info at https://revealjs.com/math/
				plugins: [ RevealMath.MathJax2 ]
			});
		</script>
	</body>
</html>
